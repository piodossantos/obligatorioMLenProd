{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3f519b94-fcbe-48cf-ab33-e3f2ce2c5c65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f519b94-fcbe-48cf-ab33-e3f2ce2c5c65",
        "outputId": "3b84cf4a-05a5-4107-b343-69646b667d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-storage-blob\n",
            "  Downloading azure_storage_blob-12.16.0-py3-none-any.whl (387 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/388.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.26.0 (from azure-storage-blob)\n",
            "  Downloading azure_core-1.27.1-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cryptography>=2.1.4 (from azure-storage-blob)\n",
            "  Downloading cryptography-41.0.1-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (4.6.3)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.26.0->azure-storage-blob) (2.27.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.26.0->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (3.4)\n",
            "Installing collected packages: isodate, cryptography, azure-core, azure-storage-blob\n",
            "Successfully installed azure-core-1.27.1 azure-storage-blob-12.16.0 cryptography-41.0.1 isodate-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install azure-storage-blob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "faf52958-616c-4283-a1b0-4ddeb7996de7",
      "metadata": {
        "id": "faf52958-616c-4283-a1b0-4ddeb7996de7"
      },
      "outputs": [],
      "source": [
        "#!pip install azure-storage-blob\n",
        "\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
        "\n",
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=mloblistorage;AccountKey=u+SGxSxdN+0KtUq2qwRS2zD+Ul4hBnt+nhAzPok53QggOuXa9+5V3VU8NDHiGmG2zN+ghQ7V+AtY+ASt8kPFcA==;EndpointSuffix=core.windows.net\"\n",
        "container_name =\"mloblistoragecontainer\"\n",
        "blob_name = \"properties_tienda_inglesa.csv\"\n",
        "\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "\n",
        "blob_client = container_client.get_blob_client(blob_name)\n",
        "csv_data = blob_client.download_blob().content_as_text()\n",
        "\n",
        "data = StringIO(csv_data)\n",
        "df = pd.read_csv(data, header=None, names=['id','image_urls','images','link','product_name','property_type','source','url'])\n",
        "#id,image_urls,images,link,product_name,property_type,source,url\n",
        "\n",
        "valid_categories=[\"WAREHOUSE\",\n",
        "             \"DRINKS\",\n",
        "            \"CLEANING\",\n",
        "             \"FROZEN\",\n",
        "            \"TECHNOLOGY\",\n",
        "             \"PERFUMERY\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "23b507da-2aa1-4731-aca4-15140364668c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23b507da-2aa1-4731-aca4-15140364668c",
        "outputId": "c4c02478-7b95-4b9b-cb37-4fb19b2fbbfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-214b070c72a5>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['md5']=''\n"
          ]
        }
      ],
      "source": [
        "df = df_filtrado = df.query('property_type in @valid_categories')\n",
        "df = df[~df['id'].duplicated()]\n",
        "df['md5']=''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_from_blob(blob_client):\n",
        "    stream = io.BytesIO()\n",
        "    download_stream = blob_client.download_blob()\n",
        "    stream.write(download_stream.readall())\n",
        "\n",
        "    stream.seek(0)\n",
        "    image = Image.open(stream)\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "NDB5G1CaMIRD"
      },
      "id": "NDB5G1CaMIRD",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(blob_client, blob_name):\n",
        "\n",
        "    image = get_image_from_blob(blob_client, blob_name)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "FkxT7hoU9khI"
      },
      "id": "FkxT7hoU9khI",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d920230f-0505-46a5-ae66-5b985dc92b90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d920230f-0505-46a5-ae66-5b985dc92b90",
        "outputId": "b863f5b9-e5ac-46fd-bcb2-ec6f83f02fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception:\n",
            "get_image_from_blob() takes 1 positional argument but 2 were given\n"
          ]
        }
      ],
      "source": [
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
        "import io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "    blob_name = 'full/0094e2445afde938bd97477f21149e43101f1ebf.jpg'\n",
        "    blob_client = blob_service_client.get_blob_client(container_name, blob_name)\n",
        "\n",
        "    show_image(blob_client, blob_name)\n",
        "\n",
        "except Exception as ex:\n",
        "    print('Exception:')\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_md5(imagen):\n",
        "    md5_hash = hashlib.md5(imagen).hexdigest()\n",
        "    return md5_hash"
      ],
      "metadata": {
        "id": "bvamEBoTpBML"
      },
      "id": "bvamEBoTpBML",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE=32"
      ],
      "metadata": {
        "id": "VTkUenP5qq8i"
      },
      "id": "VTkUenP5qq8i",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import ast\n",
        "import hashlib\n",
        "\n",
        "image_ids=[]\n",
        "images =[]\n",
        "categories=[]\n",
        "count=1;\n",
        "for index, row in df.iterrows():\n",
        "    lista_json = row['images']\n",
        "    b=ast.literal_eval(lista_json[1:-1])\n",
        "    path =  b.get(\"path\")\n",
        "\n",
        "    blob_client = blob_service_client.get_blob_client(container_name, path)\n",
        "    imagen=get_image_from_blob(blob_client).resize((IMAGE_SIZE,IMAGE_SIZE))\n",
        "    md5=calcular_md5(imagen.tobytes())\n",
        "    if(md5 not in df['md5'].values):\n",
        "      images.append(imagen)\n",
        "      df.at[index,'md5'] = md5\n",
        "\n",
        "      image_ids.append(row['id'])\n",
        "      categories.append(row['property_type'])\n",
        "      if count%100==0:\n",
        "        print(f\"Load {count} images of {df.shape[0]}\")\n",
        "      count+=1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28caMdya8bwm",
        "outputId": "d7ddc155-19de-4eeb-8d8a-aefc59abce29"
      },
      "id": "28caMdya8bwm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load 100 images of 6229\n",
            "Load 200 images of 6229\n",
            "Load 300 images of 6229\n",
            "Load 400 images of 6229\n",
            "Load 500 images of 6229\n",
            "Load 600 images of 6229\n",
            "Load 700 images of 6229\n",
            "Load 800 images of 6229\n",
            "Load 900 images of 6229\n",
            "Load 1000 images of 6229\n",
            "Load 1100 images of 6229\n",
            "Load 1200 images of 6229\n",
            "Load 1300 images of 6229\n",
            "Load 1400 images of 6229\n",
            "Load 1500 images of 6229\n",
            "Load 1600 images of 6229\n",
            "Load 1700 images of 6229\n",
            "Load 1800 images of 6229\n",
            "Load 1900 images of 6229\n",
            "Load 2000 images of 6229\n",
            "Load 2100 images of 6229\n",
            "Load 2200 images of 6229\n",
            "Load 2300 images of 6229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "N5GPQwIMrJoB"
      },
      "id": "N5GPQwIMrJoB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "def convert_image_to_example(image, image_id,category):\n",
        "    feature = {\n",
        "        'id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(image_id).encode()])),\n",
        "        'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image.tobytes()])),\n",
        "        'property_type': tf.train.Feature(bytes_list=tf.train.BytesList(value=[category.encode()])),\n",
        "    }\n",
        "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    return example_proto.SerializeToString()\n",
        "\n",
        "def save_images_to_tfrecords(images, image_ids,categories ,output_file):\n",
        "    with tf.io.TFRecordWriter(output_file) as writer:\n",
        "        for image, category in zip(zip(images, image_ids),categories):\n",
        "            tf_example = convert_image_to_example(image[0],image[1], category)\n",
        "            writer.write(tf_example)\n",
        "\n",
        "\n",
        "# Guardar las imagenes y sus IDs en un archivo TFRecords\n",
        "save_images_to_tfrecords(images, image_ids, categories ,'images.tfrecords')\n",
        "\n"
      ],
      "metadata": {
        "id": "TVQ2uVKhBlfp"
      },
      "id": "TVQ2uVKhBlfp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para leer un archivo TFRecords y recuperar las imágenes y sus IDs\n",
        "def read_images_from_tfrecords(input_file):\n",
        "    raw_dataset = tf.data.TFRecordDataset(input_file)\n",
        "    count=0\n",
        "    for _ in raw_dataset:\n",
        "      count+=1\n",
        "\n",
        "    print(count)\n",
        "    feature_description = {\n",
        "        'id': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'property_type': tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "\n",
        "\n",
        "    images = []\n",
        "    image_ids = []\n",
        "    property_types =[]\n",
        "    for raw_record in raw_dataset:\n",
        "        example = tf.train.Example()\n",
        "        example.ParseFromString(raw_record.numpy())\n",
        "        image_bytes = example.features.feature['image'].bytes_list.value[0]\n",
        "        image = Image.frombytes('RGB', (32, 32), image_bytes)\n",
        "\n",
        "        image_id = example.features.feature['id'].bytes_list.value[0].decode()\n",
        "        property_type = example.features.feature['property_type'].bytes_list.value[0].decode()\n",
        "\n",
        "        images.append(image)\n",
        "        property_types.append(property_type)\n",
        "\n",
        "\n",
        "    return images, image_ids, property_types\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Leer el archivo TFRecords y recuperar las imágenes y sus IDs\n",
        "loaded_images, loaded_image_ids, property_types = read_images_from_tfrecords('images.tfrecords')"
      ],
      "metadata": {
        "id": "fcQWVZiuE0rv"
      },
      "id": "fcQWVZiuE0rv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loaded_images)"
      ],
      "metadata": {
        "id": "y7vkUmbURtKS"
      },
      "id": "y7vkUmbURtKS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}